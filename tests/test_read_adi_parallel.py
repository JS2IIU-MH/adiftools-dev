"""
Unit tests for read_adi_parallel bug fixes

Tests cover:
1. chunk_size == 0 bug when num_processes > number of records
2. Multi-line record handling
3. Robust field extraction regex
4. Large file handling with proper record splitting
"""
import pytest
import tempfile
from pathlib import Path

from adiftools import adiftools


@pytest.fixture
def single_record_file():
    """Create a temporary file with a single ADIF record"""
    content = """Generated by test
<ADIF_VER:4>2.25
<EOH>

<CALL:6>TEST01 <MODE:3>FT8 <QSO_DATE:8>20210101 <TIME_ON:6>120000 <BAND:3>40m <EOR>
"""
    with tempfile.NamedTemporaryFile(mode='w', suffix='.adi', delete=False) as f:
        f.write(content)
        path = Path(f.name)
    yield path
    path.unlink()


@pytest.fixture
def multiline_record_file():
    """Create a temporary file with multi-line ADIF records"""
    content = """Generated by test
<EOH>

<CALL:6>TEST01 <MODE:3>FT8 
<QSO_DATE:8>20210101 <TIME_ON:6>120000 
<BAND:3>40m <EOR>
<CALL:6>TEST02 <MODE:3>CW 
<QSO_DATE:8>20210102 
<TIME_ON:6>130000 <BAND:3>20m <EOR>
<CALL:6>TEST03 <MODE:3>SSB <QSO_DATE:8>20210103 <TIME_ON:6>140000 <BAND:3>15m <EOR>
"""
    with tempfile.NamedTemporaryFile(mode='w', suffix='.adi', delete=False) as f:
        f.write(content)
        path = Path(f.name)
    yield path
    path.unlink()


@pytest.fixture
def large_record_file():
    """Create a file with many records to test chunking"""
    content = """Generated by test
<EOH>

"""
    # Generate 50 test records
    for i in range(1, 51):
        content += f"<CALL:7>TEST{i:03d} <MODE:3>FT8 <QSO_DATE:8>2021010{(i % 9) + 1} <TIME_ON:6>12{i:04d} <BAND:3>40m <EOR>\n"
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.adi', delete=False) as f:
        f.write(content)
        path = Path(f.name)
    yield path
    path.unlink()


@pytest.fixture
def case_insensitive_file():
    """Create a file with mixed case EOR tags"""
    content = """Generated by test
<eoh>

<CALL:6>TEST01 <MODE:3>FT8 <QSO_DATE:8>20210101 <TIME_ON:6>120000 <BAND:3>40m <eor>
<call:6>TEST02 <mode:3>CW <qso_date:8>20210102 <time_on:6>130000 <band:3>20m <EOR>
<CALL:6>TEST03 <MODE:3>SSB <QSO_DATE:8>20210103 <TIME_ON:6>140000 <BAND:3>15m <Eor>
"""
    with tempfile.NamedTemporaryFile(mode='w', suffix='.adi', delete=False) as f:
        f.write(content)
        path = Path(f.name)
    yield path
    path.unlink()


def test_chunk_size_zero_bug(single_record_file):
    """Test that chunk_size == 0 bug is fixed when num_processes > records"""
    parser = adiftools.ADIFParser()
    
    # This should not raise "range() arg 3 must not be zero"
    df = parser.read_adi_parallel(single_record_file, num_processes=4)
    
    assert len(df) == 1
    assert df['CALL'].iloc[0] == 'TEST01'
    assert df['MODE'].iloc[0] == 'FT8'
    assert df['BAND'].iloc[0] == '40M'


def test_multiline_records(multiline_record_file):
    """Test that multi-line records are properly parsed"""
    parser = adiftools.ADIFParser()
    
    df = parser.read_adi_parallel(multiline_record_file, num_processes=2)
    
    assert len(df) == 3
    assert df['CALL'].tolist() == ['TEST01', 'TEST02', 'TEST03']
    assert df['MODE'].tolist() == ['FT8', 'CW', 'SSB']
    assert df['BAND'].tolist() == ['40M', '20M', '15M']


def test_large_file_chunking(large_record_file):
    """Test proper chunking with many records"""
    parser = adiftools.ADIFParser()
    
    # Test with various numbers of processes
    for num_proc in [1, 2, 4, 8]:
        df = parser.read_adi_parallel(large_record_file, num_processes=num_proc)
        assert len(df) == 50
        # Verify all records are unique
        assert len(df['CALL'].unique()) == 50


def test_case_insensitive_tags(case_insensitive_file):
    """Test that case-insensitive <EOR> and <EOH> tags are handled"""
    parser = adiftools.ADIFParser()
    
    df = parser.read_adi_parallel(case_insensitive_file, num_processes=2)
    
    assert len(df) == 3
    assert df['CALL'].tolist() == ['TEST01', 'TEST02', 'TEST03']


def test_parallel_vs_serial_consistency(large_record_file):
    """Test that parallel parsing produces consistent results regardless of num_processes"""
    # Compare different parallel configurations rather than serial vs parallel
    # since serial read_adi has different behavior with multi-line records
    parser1 = adiftools.ADIFParser()
    parser2 = adiftools.ADIFParser()
    parser3 = adiftools.ADIFParser()
    
    df1 = parser1.read_adi_parallel(large_record_file, num_processes=1)
    df2 = parser2.read_adi_parallel(large_record_file, num_processes=2)
    df3 = parser3.read_adi_parallel(large_record_file, num_processes=4)
    
    # All should have same number of records
    assert len(df1) == len(df2) == len(df3)
    
    # Sort all by CALL to ensure consistent comparison
    df1 = df1.sort_values('CALL').reset_index(drop=True)
    df2 = df2.sort_values('CALL').reset_index(drop=True)
    df3 = df3.sort_values('CALL').reset_index(drop=True)
    
    # Check all calls match
    assert df1['CALL'].tolist() == df2['CALL'].tolist() == df3['CALL'].tolist()


def test_empty_records_filtered():
    """Test that empty records are properly filtered out"""
    content = """<EOH>

<CALL:6>TEST01 <MODE:3>FT8 <QSO_DATE:8>20210101 <TIME_ON:6>120000 <BAND:3>40m <EOR>

<EOR>

<CALL:6>TEST02 <MODE:3>CW <QSO_DATE:8>20210102 <TIME_ON:6>130000 <BAND:3>20m <EOR>
"""
    with tempfile.NamedTemporaryFile(mode='w', suffix='.adi', delete=False) as f:
        f.write(content)
        path = Path(f.name)
    
    try:
        parser = adiftools.ADIFParser()
        df = parser.read_adi_parallel(path, num_processes=2)
        
        # Should only have 2 valid records, empty one should be filtered
        assert len(df) == 2
        assert df['CALL'].tolist() == ['TEST01', 'TEST02']
    finally:
        path.unlink()


def test_robust_field_extraction():
    """Test that field extraction handles various ADIF field formats"""
    # Test with fields that have type indicators
    content = """<EOH>

<CALL:6>TEST01 <MODE:3>FT8 <FREQ:9:N>14.074000 <QSO_DATE:8:D>20210101 <TIME_ON:6:T>120000 <BAND:3>20m <EOR>
"""
    with tempfile.NamedTemporaryFile(mode='w', suffix='.adi', delete=False) as f:
        f.write(content)
        path = Path(f.name)
    
    try:
        parser = adiftools.ADIFParser()
        df = parser.read_adi_parallel(path, num_processes=1)
        
        assert len(df) == 1
        assert df['CALL'].iloc[0] == 'TEST01'
        assert df['MODE'].iloc[0] == 'FT8'
        assert 'FREQ' in df.columns
        assert 'QSO_DATE' in df.columns
    finally:
        path.unlink()


def test_num_processes_auto_detect(single_record_file):
    """Test that num_processes=None uses CPU count"""
    parser = adiftools.ADIFParser()
    
    # Should not raise an error with default num_processes
    df = parser.read_adi_parallel(single_record_file)
    
    assert len(df) == 1
    assert df['CALL'].iloc[0] == 'TEST01'


def test_single_process_mode(multiline_record_file):
    """Test that single process mode (num_processes=1) works correctly"""
    parser = adiftools.ADIFParser()
    
    df = parser.read_adi_parallel(multiline_record_file, num_processes=1)
    
    assert len(df) == 3
    assert df['CALL'].tolist() == ['TEST01', 'TEST02', 'TEST03']
